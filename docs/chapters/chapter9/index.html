<!DOCTYPE html>
<html lang="en-us">
<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<title>Chapter 9 - DATA 606 - Statistics &amp; Probability - Spring 2022</title>
<meta name="generator" content="Hugo 0.60.0" />
<link href="//index.xml" rel="alternate" type="application/rss+xml">
<link rel="canonical" href="/chapters/chapter9/">
<link rel="stylesheet" href="/css/theme.min.css">
<script src="https://use.fontawesome.com/releases/v5.0.6/js/all.js"></script>
<link rel="stylesheet" href="/css/chroma.min.css">
<script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/jquery.easing@1.4.1/jquery.easing.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.6/dist/clipboard.min.js"></script>
<script src="/js/bundle.js"></script><style>
:root {--custom-background-color: #003366;}
</style>
<meta property="og:title" content="Chapter 9" />
<meta property="og:description" content="MathJax.Hub.Config({ tex2jax: { inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]], displayMath: [[&#39;$$&#39;,&#39;$$&#39;], [&#39;\[&#39;,&#39;\]&#39;]], processEscapes: true, processEnvironments: true, skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;], TeX: { equationNumbers: { autoNumber: &#34;AMS&#34; }, extensions: [&#34;AMSmath.js&#34;, &#34;AMSsymbols.js&#34;] } } });   Multiple and Logistic Regression Learning Outcomes  Define the multiple linear regression model as $$\hat{y} = \beta_0 &#43; \beta_1 x_1 &#43; \beta_2 x_2 &#43; \cdots &#43; \beta_k x_k$$ where there are $k$ predictors (explanatory variables). Interpret the estimate for the intercept ($b_0$) as the expected value of $y$ when all predictors are equal to 0, on average." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/chapters/chapter9/" />
<meta property="og:image" content="/images/og-image.png"/>
<meta property="article:published_time" content="2017-04-29T18:36:24+02:00" />
<meta property="article:modified_time" content="2017-04-29T18:36:24+02:00" /><meta property="og:site_name" content="DATA 606" />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="/images/og-image.png"/>

<meta name="twitter:title" content="Chapter 9"/>
<meta name="twitter:description" content="MathJax.Hub.Config({ tex2jax: { inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]], displayMath: [[&#39;$$&#39;,&#39;$$&#39;], [&#39;\[&#39;,&#39;\]&#39;]], processEscapes: true, processEnvironments: true, skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;], TeX: { equationNumbers: { autoNumber: &#34;AMS&#34; }, extensions: [&#34;AMSmath.js&#34;, &#34;AMSsymbols.js&#34;] } } });   Multiple and Logistic Regression Learning Outcomes  Define the multiple linear regression model as $$\hat{y} = \beta_0 &#43; \beta_1 x_1 &#43; \beta_2 x_2 &#43; \cdots &#43; \beta_k x_k$$ where there are $k$ predictors (explanatory variables). Interpret the estimate for the intercept ($b_0$) as the expected value of $y$ when all predictors are equal to 0, on average."/>
<meta itemprop="name" content="Chapter 9">
<meta itemprop="description" content="MathJax.Hub.Config({ tex2jax: { inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]], displayMath: [[&#39;$$&#39;,&#39;$$&#39;], [&#39;\[&#39;,&#39;\]&#39;]], processEscapes: true, processEnvironments: true, skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;], TeX: { equationNumbers: { autoNumber: &#34;AMS&#34; }, extensions: [&#34;AMSmath.js&#34;, &#34;AMSsymbols.js&#34;] } } });   Multiple and Logistic Regression Learning Outcomes  Define the multiple linear regression model as $$\hat{y} = \beta_0 &#43; \beta_1 x_1 &#43; \beta_2 x_2 &#43; \cdots &#43; \beta_k x_k$$ where there are $k$ predictors (explanatory variables). Interpret the estimate for the intercept ($b_0$) as the expected value of $y$ when all predictors are equal to 0, on average.">
<meta itemprop="datePublished" content="2017-04-29T18:36:24&#43;02:00" />
<meta itemprop="dateModified" content="2017-04-29T18:36:24&#43;02:00" />
<meta itemprop="wordCount" content="711">
<meta itemprop="image" content="/images/og-image.png"/>



<meta itemprop="keywords" content="" /><link href='/fullcalendar-lib/main.css' rel='stylesheet' />
<script src='/fullcalendar-lib/main.js'></script>

<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest">

<style>
#calendar {
	max-width: 1100px;
	margin: 0 auto;
}
</style>
</head>
<body><div class="container"><header>

<a href="/"><img src='/images/course_logo.png' align="left" style="height:40px; padding-right:10px;border:0;" /></a><h1>DATA 606 - Statistics &amp; Probability - Spring 2022</h1>
</header>
<div class="global-menu">
<nav>
<ul>
<li><a href="/">Home</a></li>
<li><a href="/blog">Announcements</a></li>
<li><a href="/course-overview/schedule/">Schedule</a></li>
<li><a href="/course-overview/meetups/">Meetups</a></li>
<li><a href="https://DATA606Spring2022.slack.com">Slack</a></li>
<li><a href="https://bbhosted.cuny.edu/webapps/login">Blackboard</a></li>
<li><a href="https://github.com/jbryer/DATA606Spring2022/">Github</a></li>
<li><a href="https://sps.cuny.edu/academics/graduate/master-science-data-science-ms">CUNY SPS</a></li></ul>
</nav>
</div>
<div class="content-container">
<main><h1>Chapter 9</h1>
<!-- 
See issue with underscores in MathJax equations here: https://gohugo.io/content-management/formats/#issues-with-markdown
The solution, put backticks (`) around the LaTeX equation
-->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[','\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});
</script>
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<h2 id="multiple-and-logistic-regression">Multiple and Logistic Regression</h2>
<h3 id="learning-outcomes">Learning Outcomes</h3>
<ul>
<li>Define the multiple linear regression model as
<code>$$\hat{y} = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_k x_k$$</code>
where there are $k$ predictors (explanatory variables).</li>
<li>Interpret the estimate for the intercept ($b_0$) as the expected value of $y$ when all predictors are equal to 0, on average.</li>
<li>Interpret the estimate for a slope (say $b_1$) as &ldquo;All else held constant, for each unit increase in $x_1$, we would expect $y$ to increase/decrease on average by $b_1$.&rdquo;</li>
<li>Define collinearity as a high correlation between two independent variables such that the two variables contribute redundant information to the model &ndash; which is something we want to avoid in multiple linear regression.</li>
<li>Note that $R^2$ will increase with each explanatory variable added to the model, regardless of whether or not the added variables is a meaningful predictor of the response variable. Therefore we use adjusted $R^2$, which applies a penalty for the number of predictors included in the model, to better assess the strength of a multiple linear regression model:
<code>$$R^2 = 1 - \frac{Var(e_i) / (n - k - 1)}{Var(y_i) / (n - 1)}$$</code>
where <code>$Var(e_i)$</code> measures the variability of residuals (<code>$SS_{Err}$</code>), <code>$Var(y_i)$</code> measures the total variability in observed $y$ (<code>$SS_{Tot}$</code>), $n$ is the number of cases and $k$ is the number of predictors.
<ul>
<li>Note that adjusted $R^2$ will only increase if the added variable has a meaningful contribution to the amount of explained variability in $y$, i.e. if the gains from adding the variable exceeds the penalty.</li>
</ul>
</li>
<li>Define model selection as identifying the best model for predicting a given response variable.</li>
<li>Note that we usually prefer simpler (parsimonious) models over more complicated ones.</li>
<li>Define the full model as the model with all explanatory variables included as predictors.</li>
<li>Note that the p-values associated with each predictor are conditional on other variables being included in the model, so they can be used to assess if a given predictor is significant, given that all others are in the model.
<ul>
<li>These p-values are calculated based on a $t$ distribution with $n - k - 1$ degrees of freedom.</li>
<li>The same degrees of freedom can be used to construct a confidence interval for the slope parameter of each predictor:
<code>$$b_i \pm t^\star_{n - k - 1} SE_{b_i}$$</code></li>
</ul>
</li>
<li>Stepwise model selection (backward or forward) can be done based based on adjusted $R^2$ (choose the model with higher adjusted $R^2$).</li>
<li>The general idea behind backward-selection is to start with the full model and eliminate one variable at a time until the ideal model is reached.
i. Start with the full model.
ii. Refit all possible models omitting one variable at a time, and choose the model with the highest adjusted $R^2$.
iii. Repeat until maximum possible adjusted $R^2$ is reached.</li>
<li>The general idea behind forward-selection is to start with only one variable and adding one variable at a time until the ideal model is reached.
i. Try all possible simple linear regression models predicting $y$ using one explanatory variable at a time. Choose the model with the highest adjusted $R^2$.
ii. Try all possible models adding one more explanatory variable at a time, and choose the model with the highest adjusted $R^2$.
iii. Repeat until maximum possible adjusted $R^2$ is reached.</li>
<li>Adjusted $R^2$ method is more computationally intensive, but it is more reliable, since it doesn't depend on an arbitrary significant level.</li>
<li>List the conditions for multiple linear regression as
<ol>
<li>linear relationship between each (numerical) explanatory variable and the response - checked using scatterplots of $y$ vs. each $x$, and residuals plots of $residuals$ vs. each $x$</li>
<li>nearly normal residuals with mean 0 - checked using a normal probability plot and histogram of residuals</li>
<li>constant variability of residuals - checked using residuals plots of $residuals$ vs. $\hat{y}$, and $residuals$ vs. each $x$</li>
<li>independence of residuals (and hence observations) - checked using a scatterplot of $residuals$ vs. order of data collection (will reveal non-independence if data have time series structure)</li>
</ol>
</li>
<li>Note that no model is perfect, but even imperfect models can be useful.</li>
</ul>
<h3 id="supplemental-readings">Supplemental Readings</h3>
<ul>
<li><a href="https://github.com/jbryer/DATA606Fall2020/blob/master/Slides/OpenIntro/chp9.pdf">OpenIntro Statistics slides</a></li>
</ul>
<h3 id="videos">Videos</h3>
<iframe width="560" height="315" src="https://www.youtube.com/embed/sQpAuyfEYZg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<iframe width="560" height="315" src="https://www.youtube.com/embed/VB1qSwoF-l0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<iframe width="560" height="315" src="https://www.youtube.com/embed/3KSUeYMKt5A" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<iframe width="560" height="315" src="https://www.youtube.com/embed/uYC2eLVSpI8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<iframe width="560" height="315" src="https://www.youtube.com/embed/WflqTUOvdik" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<div class="edit-meta">
Last updated on Sat Apr 29, 2017


<br>
Published on Sat Apr 29, 2017
<br><a href="https://github.com/jbryer/DATA606Spring2022/edit/main/website/content/chapters/chapter9.md" class="edit-page"><i class="fas fa-pen-square"></i> Edit on GitHub</a></div><nav class="pagination"><a class="nav nav-prev" href="/chapters/chapter8/" title="Chapter 8"><i class="fas fa-arrow-left" aria-hidden="true"></i> Prev - Chapter 8</a>
<a class="nav nav-next" href="/chapters/bayesian/" title="Bayesian">Next - Bayesian <i class="fas fa-arrow-right" aria-hidden="true"></i></a>
</nav><footer><p class="powered">Powered by <a href="https://gohugo.io">Hugo</a>. Theme by <a href="https://themes.gohugo.io/hugo-theme-techdoc/">TechDoc</a>. Designed by <a href="https://github.com/thingsym/hugo-theme-techdoc">Thingsym</a>.</p>
</footer>
</main>
<div class="sidebar">

<nav class="open-menu">
<ul>
<li class=""><a href="/">Home</a></li>



<li class=""><a href="/course-overview/">Syllabus</a>
  
<ul class="sub-menu">
<li class=""><a href="/course-overview/instructor/">Instructors</a></li>
<li class=""><a href="/course-overview/schedule/">Schedule</a></li>
<li class=""><a href="/course-overview/meetups/">Meetups</a></li>
<li class=""><a href="/course-overview/textbooks/">Textbooks</a></li>
<li class=""><a href="/course-overview/software/">Software</a></li>
<li class=""><a href="/course-overview/mathjax/">Math Equations</a></li>
<li class=""><a href="/course-overview/materials/">Materials</a></li>
</ul>
  
</li>

<li class=""><a href="/assignments/">Assignments</a>
  
<ul class="sub-menu">
<li class=""><a href="/assignments/daacs/">DAACS</a></li>
<li class=""><a href="/assignments/participation/">Participation</a></li>
<li class=""><a href="/assignments/labs/">Labs</a></li>
<li class=""><a href="/assignments/project/">Project</a></li>
<li class=""><a href="/assignments/exams/">Exams</a></li>
<li class=""><a href="/assignments/homework_ungraded/">Homework</a></li>
</ul>
  
</li>

<li class="parent"><a href="/chapters/">Chapters</a>
  
<ul class="sub-menu">
<li class=""><a href="/chapters/chapter1/">Chapter 1</a></li>
<li class=""><a href="/chapters/chapter2/">Chapter 2</a></li>
<li class=""><a href="/chapters/chapter3/">Chapter 3</a></li>
<li class=""><a href="/chapters/chapter4/">Chapter 4</a></li>
<li class=""><a href="/chapters/chapter5/">Chapter 5</a></li>
<li class=""><a href="/chapters/chapter6/">Chapter 6</a></li>
<li class=""><a href="/chapters/chapter7/">Chapter 7</a></li>
<li class=""><a href="/chapters/chapter8/">Chapter 8</a></li>
<li class="active"><a href="/chapters/chapter9/">Chapter 9</a></li>
<li class=""><a href="/chapters/bayesian/">Bayesian</a></li>
</ul>
  
</li>
</ul>
</nav>



<div class="sidebar-footer"></div>
</div>

</div><a href="#" id="backtothetop-fixed" class="backtothetop"
 data-backtothetop-duration="600"
 data-backtothetop-easing="easeOutQuart"
 data-backtothetop-fixed-fadeIn="1000"
 data-backtothetop-fixed-fadeOut="1000"
 data-backtothetop-fixed-bottom="10"
 data-backtothetop-fixed-right="20">
<span class="fa-layers fa-fw">
<i class="fas fa-circle"></i>
<i class="fas fa-arrow-circle-up"></i>
</span></a>
</div>
</body>
</html>
