---
title: "Foundation for Inference Part 1"
subtitle: "DATA 606 - Statistics & Probability for Data Analytics"
author: Jason Bryer, Ph.D. and Angela Lui, Ph.D.
date: "March 2, 2022"
output:
  xaringan::moon_reader:
    css: ["assets/mtheme_max.css", "assets/fonts_mtheme_max.css"]
    lib_dir: libs
    nature:
      highlightStyle: solarized-light
      highlightLanguage: R
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
      navigation:
        scroll: false
    includes:
      in_header: [assets/header.html]
      after_body: [assets/insert-logo.html]
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE}
# Cartoons from https://github.com/allisonhorst/stats-illustrations
# dplyr based upon https://allisonhorst.shinyapps.io/dplyr-learnr/#section-welcome

source('config.R')
```

# One Minute Paper Results

```{r, echo=FALSE}
library(googlesheets4)
omp <- read_sheet(one_minute_paper_results)
omp <- omp %>% dplyr::filter(Topic == 'Distributions (Chapter 4)')
source('word_cloud.R')
```

.pull-left[
**What was the most important thing you learned during this class?**
```{r, echo=FALSE, fig.height=9}
ompWordCloud(omp$`What was the most important thing you learned during this class?`)
```
]
.pull-right[
**What important question remains unanswered for you?**
```{r, echo=FALSE, fig.height=9}
ompWordCloud(omp$`What important question remains unanswered for you?`)
```
]


---
class: center, middle, inverse
# Crash Course in Calculus 

---
class: font90
# Crash Course in Calculus

There are three major concepts in calculus that will be helpful to understand:

**Limits** - the value that a function (or sequence) approaches as the input (or index) approaches some value.

**Derivatives** - the slope of the line tangent at any given point on a function.

```{r, echo=FALSE, fig.height=2, fig.width=4, results = 'hide'}
library(Deriv)
x <- 5
xlimits <- c(-5, 15)
f <- function(x) { 0.015 * x^3 - 0.25 * x^2 + 0.49 * x + 0.47 }
dx <- Deriv(f)
dx(x)
ggplot() + stat_function(fun = f) + xlim(xlimits) +
	geom_point(aes(x = x, y = f(x)), color = 'blue', size = 3) +
	geom_abline(slope = dx(x)[1], intercept = f(x) - dx(x)[1] * x, color = 'blue')

```

**Integrals** - the area under the curve.

```{r, echo=FALSE, fig.height=2, fig.width=4}
normal_plot(cv = c(0, 2)) + ggtitle(label = NULL)
```

---
background-image: url(images/derivative_1.jpg)
background-size: contain
# Derivatives

<div class="my-footer"><span>
Source: <a href='https://github.com/allisonhorst/stats-illustrations'>@allison_horst</a>
</span></div>

---
background-image: url(images/derivative_2.jpg)
background-size: contain
# Derivatives

<div class="my-footer"><span>
Source: <a href='https://github.com/allisonhorst/stats-illustrations'>@allison_horst</a>
</span></div>

---
background-image: url(images/derivative_3.jpg)
background-size: contain
# Derivatives

<div class="my-footer"><span>
Source: <a href='https://github.com/allisonhorst/stats-illustrations'>@allison_horst</a>
</span></div>

---
background-image: url(images/derivative_4.jpg)
background-size: contain
# Derivatives

<div class="my-footer"><span>
Source: <a href='https://github.com/allisonhorst/stats-illustrations'>@allison_horst</a>
</span></div>

---
background-image: url(images/derivative_5.jpg)
background-size: contain
# Derivatives

<div class="my-footer"><span>
Source: <a href='https://github.com/allisonhorst/stats-illustrations'>@allison_horst</a>
</span></div>

---
background-image: url(images/derivative_6.jpg)
background-size: contain
# Derivatives

<div class="my-footer"><span>
Source: <a href='https://github.com/allisonhorst/stats-illustrations'>@allison_horst</a>
</span></div>

---
background-image: url(images/derivative_7.jpg)
background-size: contain
# Derivatives

<div class="my-footer"><span>
Source: <a href='https://github.com/allisonhorst/stats-illustrations'>@allison_horst</a>
</span></div>

---
background-image: url(images/derivative_8.jpg)
background-size: contain
# Derivatives

<div class="my-footer"><span>
Source: <a href='https://github.com/allisonhorst/stats-illustrations'>@allison_horst</a>
</span></div>

---
background-image: url(images/derivative_9.jpg)
background-size: contain
# Derivatives

<div class="my-footer"><span>
Source: <a href='https://github.com/allisonhorst/stats-illustrations'>@allison_horst</a>
</span></div>

---
# Function for Normal Distribution

$$f\left( x|\mu ,\sigma  \right) =\frac { 1 }{ \sigma \sqrt { 2\pi  }  } { e }^{ -\frac { { \left( x-\mu  \right)  }^{ 2 } }{ { 2\sigma  }^{ 2 } }  }$$

```{r}
f <- function(x, mean = 0, sigma = 1) {
	1 / (sigma * sqrt(2 * pi)) * exp(1)^(-1/2 * ( (x - mean) / sigma )^2)
}
```

```{r, fig.height=3.5}
min <- 0; max <- 2
ggplot() + stat_function(fun = f) + xlim(c(-4, 4)) + 
	geom_vline(xintercept = c(min, max), color = 'blue', linetype = 2) + xlab('x')
```


---
# Reimann Sums

One strategy to find the area between two values is to draw a series of rectangles. Given *n* rectangles, we know that the width of each is $\frac{2 - 0}{n}$ and the height is $f(x)$. Here is an example with 3 rectangles.

```{r, echo=FALSE}
riemann <- function(f, min, max, n = 2) {
	width <- (max - min) / n
	boxes <- tibble(
		xmin = seq(min, min + (n-1) * width, by = width),
		height = f(xmin),
		area = height * width
	)
	return(boxes)
}
```

```{r, fig.height=3.5, echo = FALSE}
n <- 3
boxes <- riemann(f, min, max, n = n)
width <- (max-min)/n
ggplot() +
	geom_rect(data = boxes, aes(xmin = xmin, ymin = 0, xmax = xmin + width, ymax = height),
			  alpha = 0.5, color = 'black') +
	stat_function(fun = f) + xlim(c(-4, 4)) +
	ggtitle(paste0('Area ≈ ', prettyNum(sum(boxes$area)), digits = 4))
```

---
# Reimann Sums (10 rectangles)

```{r, fig.height=3.5, echo = FALSE}
n <- 10
boxes <- riemann(f, min, max, n = n)
width <- (max-min)/n
ggplot() +
	geom_rect(data = boxes, aes(xmin = xmin, ymin = 0, xmax = xmin + width, ymax = height),
			  alpha = 0.5, color = 'black') +
	stat_function(fun = f) + xlim(c(-4, 4)) +
	ggtitle(paste0('Area ≈ ', prettyNum(sum(boxes$area)), digits = 4))
```

---
# Reimann Sums (30 rectangles)

```{r, fig.height=3.5, echo = FALSE}
n <- 30
boxes <- riemann(f, min, max, n = n)
width <- (max-min)/n
ggplot() +
	geom_rect(data = boxes, aes(xmin = xmin, ymin = 0, xmax = xmin + width, ymax = height),
			  alpha = 0.5, color = 'black') +
	stat_function(fun = f) + xlim(c(-4, 4)) +
	ggtitle(paste0('Area ≈ ', prettyNum(sum(boxes$area)), digits = 4))
```

---
# Reimann Sums (300 rectangles)

```{r, fig.height=3.5, echo = FALSE}
n <- 300
boxes <- riemann(f, min, max, n = n)
width <- (max-min)/n
ggplot() +
	geom_rect(data = boxes, aes(xmin = xmin, ymin = 0, xmax = xmin + width, ymax = height),
			  alpha = 0.5, color = 'black') +
	stat_function(fun = f) + xlim(c(-4, 4)) +
	ggtitle(paste0('Area ≈ ', prettyNum(sum(boxes$area)), digits = 4))
```

---
# $n\rightarrow \infty$

As *n* approaches infinity we are going to get the *exact* value for the area under the curve. This notion of letting a value get increasingly close to infinity, zero, or any other value, is called the **limit**.

The area under a function is called the integral.

```{r}
integrate(f, 0, 2)
```

```{r, eval=FALSE}
DATA606::shiny_demo('calculus')
```

---
# Normal Distribution

```{r, fig.height=3.5}
normal_plot(cv = c(0, 2))
```

```{r}
pnorm(2) - pnorm(0)
```

---
# R's built in functions for working with distributions

```{r, echo=FALSE}
library(cowplot)

plot_distributions <- function(dist, xvals, xmin, xmax,
							   args = list(),
							   palette = c(d = '#1b9e77', r = '#d95f02', p = '#7570b3', q = '#e7298a')) {
	functions <- c(d = get(paste0('d', dist)),
				   r = get(paste0('r', dist)),
				   p = get(paste0('p', dist)),
				   q = get(paste0('q', dist)))

	df <- tibble(
		x = xvals,
		d = sapply(xvals, FUN = function(x) { args$x <- x; do.call(functions[['d']], args = args) }),
		p = sapply(xvals, FUN = function(x) { args$q <- x; do.call(functions[['p']], args = args) })
	)

	args_str <- ifelse(length(args) > 0,
					   paste0(names(args), ' = ', args, collapse = ', '),
					   '')

	d_plot <- ggplot(df, aes(x = x, y = d)) +
		xlim(xmin, xmax) +
		geom_function(fun = functions[['d']], args = args) +
		geom_segment(aes(x = x, xend = x, y = 0, yend = d), color = palette['d']) +
		geom_segment(aes(x = x, xend = xmin, y = d, yend = d), color = palette['d'],
					 arrow = arrow(length = unit(0.5, "cm"))) +
		geom_point(aes(x = x, y = 0), color = palette['d'], size = 2) +
		xlab('z-score / quantile') + ylab('Probability Density') +
		ggtitle(paste0('d', dist, '(', args_str, ')'))

	r_plot <- ggplot(df, aes(x = x, y = d)) +
		xlim(xmin, xmax) +
		geom_function(fun = functions[['d']], args = args) +
		geom_segment(aes(x = x, xend = x, y = d, yend = 0), color = palette['r'],
					 arrow = arrow(length = unit(0.5, "cm"))) +
		xlab('z-score / quantile') + ylab('Probability Density') +
		ggtitle(paste0('r', dist, '(', args_str, ')'))

	p_plot <- ggplot(df, aes(x = x, y = d)) +
		xlim(xmin, xmax) +
		geom_function(fun = functions[['p']], args = args) +
		geom_segment(aes(x = x, xend = x, y = 0, yend = p), color = palette['p']) +
		geom_segment(aes(x = x, xend = xmin, y = p, yend = p), color = palette['p'],
					 arrow = arrow(length = unit(0.5, "cm"))) +
		geom_point(aes(x = x, y = 0), color = palette['p'], size = 2) +
		xlab('z-score / quantile') + ylab('Cumulative Probability') +
		ggtitle(paste0('p', dist, '(', args_str, ')'))

	q_plot <- ggplot(df, aes(x = x, y = d)) +
		xlim(xmin, xmax) +
		geom_function(fun = functions[['p']], args = args) +
		geom_segment(aes(x = x, xend = x, y = p, yend = 0), color = palette['q'],
					 arrow = arrow(length = unit(0.5, "cm"))) +
		geom_segment(aes(x = x, xend = xmin, y = p, yend = p), color = palette['q']) +
		geom_point(aes(x = xmin, y = p), color = palette['q'], size = 2) +
		xlab('z-score / quantile') + ylab('Cumulative Probability') +
		ggtitle(paste0('q', dist, '(', args_str, ')'))

	plot_grid(d_plot, r_plot, p_plot, q_plot)
}
```

```{r, echo=FALSE, fig.height=7}
plot_distributions(dist = 'norm',
				   xvals = c(-1, 0, 0.5),
				   xmin = -4, xmax = 4)
```

.font70[See https://github.com/jbryer/DATA606Fall2021/blob/master/R/distributions.R]

---
class: center, middle, inverse
# Foundation for Inference 


---
# Population Distribution (Uniform)

```{r, fig.width=10, fig.height=6}
n <- 1e5
pop <- runif(n, 0, 1)
mean(pop)
```


```{r, echo=FALSE, fig.width=10,fig.height=5, fig.align='center'}
d <- density(pop)
h <- hist(pop, plot=FALSE)
hist(pop, main='Population Distribution', xlab="", freq=FALSE, 
     ylim=c(0, max(d$y, h$density)+.5), col=COL[1,2], border = "white", 
	 cex.main = 1.5, cex.axis = 1.5, cex.lab = 1.5)
lines(d, lwd=3)
```

---
# Random Sample (n=10)

```{r, fig.width=10, fig.height=5,fig.align='center'}
samp1 <- sample(pop, size=10)
mean(samp1)
```

```{r, fig.width=10,fig.height=5,fig.align='center'}
hist(samp1)
```

---
# Random Sample (n=30)

```{r, fig.width=10,fig.height=5,fig.align='center'}
samp2 <- sample(pop, size=30)
mean(samp2)
```


```{r, fig.width=10,fig.height=5,fig.align='center'}
hist(samp2)
```

---
# Lots of Random Samples

```{r, echo=TRUE}
M <- 1000
samples <- numeric(length=M)
for(i in seq_len(M)) {
	samples[i] <- mean(sample(pop, size=30))
}
head(samples, n=8)
```


---
# Sampling Distribution


```{r, fig.width=10, fig.height=5,fig.align='center'}
hist(samples)
```



---
# Central Limit Theorem (CLT)

Let $X_1$, $X_2$, ..., $X_n$ be independent, identically distributed random variables with mean $\mu$ and variance $\sigma^2$, both finite. Then for any constant $z$,

$$ \underset { n\rightarrow \infty  }{ lim } P\left( \frac { \bar { X } -\mu  }{ \sigma /\sqrt { n }  } \le z \right) =\Phi \left( z \right)  $$

where $\Phi$ is the cumulative distribution function (cdf) of the standard normal distribution.


---
# In other words...

The distribution of the sample mean is well approximated by a normal model:

$$ \bar { x } \sim N\left( mean=\mu ,SE=\frac { \sigma  }{ \sqrt { n }  }  \right)  $$

where SE represents the **standard error**, which is defined as the standard deviation of the sampling distribution. In most cases $\sigma$ is not known, so use $s$.


---
# CLT Shiny App

```{r, eval=FALSE}
library(DATA606)
shiny_demo('sampdist')
shiny_demo('CLT_mean')
```

---
# Standard Error

```{r}
samp2 <- sample(pop, size=30)
mean(samp2)
(samp2.se <- sd(samp2) / sqrt(length(samp2)))
```

---
# Confidence Interval

The confidence interval is then $\mu \pm CV \times SE$ where CV is the critical value. For a 95% confidence interval, the critical value is ~1.96 since

$$\int _{ -1.96 }^{ 1.96 }{ \frac { 1 }{ \sigma \sqrt { 2\pi  }  } { d }^{ -\frac { { \left( x-\mu  \right)  }^{ 2 } }{ 2{ \sigma  }^{ 2 } }  } } \approx 0.95$$

```{r}
qnorm(0.025) # Remember we need to consider the two tails, 2.5% to the left, 2.5% to the right.
```

```{r}
(samp2.ci <- c(mean(samp2) - 1.96 * samp2.se, mean(samp2) + 1.96 * samp2.se))
```


---
# Confidence Intervals (cont.)

We are 95% confident that the true population mean is between `r samp2.ci`. 

That is, if we were to take 100 random samples, we would expect at least 95% of those samples to have a mean within `r samp2.ci`.

```{r}
ci <- data.frame(mean=numeric(), min=numeric(), max=numeric())
for(i in seq_len(100)) {
	samp <- sample(pop, size=30)
	se <- sd(samp) / sqrt(length(samp))
	ci[i,] <- c(mean(samp),
				mean(samp) - 1.96 * se, 
				mean(samp) + 1.96 * se)
}
ci$sample <- 1:nrow(ci)
ci$sig <- ci$min < 0.5 & ci$max > 0.5
```


---
# Confidence Intervals 

```{r, eval=TRUE, fig.width=10, fig.height=6}
ggplot(ci, aes(x=min, xend=max, y=sample, yend=sample, color=sig)) + 
	geom_vline(xintercept=0.5) + 
	geom_segment() + xlab('CI') + ylab('') +
	scale_color_manual(values=c('TRUE'='grey', 'FALSE'='red'))
```



---
class: left, font140
# One Minute Paper

Complete the one minute paper: 
`r one_minute_paper`

1. What was the most important thing you learned during this class?
2. What important question remains unanswered for you?

